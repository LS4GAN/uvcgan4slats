# Unpaired Image Translation of the SLATS dataset with UVCGAN

**Description:**

**UVCGAN** ([Paper](https://openaccess.thecvf.com/content/WACV2023/html/Torbunov_UVCGAN_UNet_Vision_Transformer_Cycle-Consistent_GAN_for_Unpaired_Image-to-Image_Translation_WACV_2023_paper.html), [repo](https://github.com/LS4GAN/uvcgan))

**SLATS dataset**: the Simple Liquid Argon Track Samples 

**Anoucement:tada::tada::** We published a upgraded version of `UVCGAN`, called `UVCGANv2` ([paper](https://arxiv.org/abs/2303.16280), [repo](https://github.com/LS4GAN/uvcgan2)), that can generate even greater translations on the CelebA and AFHQ datasets. Feel free to check it out, too. Later, we will also adapt `UVCGANv2` and test it on scientific datasets.

## Download SLATS data and pre-trained models
- Download pretrained [translator models](https://zenodo.org/deposit/7809460#) from Zenodo
- Download the [SLATS dataset](https://zenodo.org/record/7809108#.ZDQ9AHbMK3A) from Zenodo

## Run inference with pretrained translator models

## Train your own model
In this part, we demonstrate how to try your own model using training on SLATS as an example. 

### Pretraining (optional but recommended)
- pretraining configuration: 
- pretraining command:

### Training:
- training configuration:
  - with pretrained generators:
  - from scratch:
- training command:

### Hyper-parameters that do make a difference and you may also consider to tune
